{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTp1GOtxd2gT9qzTkszKnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dede0702/Assistente-Virtual-RAG-para-Desastres/blob/main/Assistente_Virtual_para_Desastres_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        " 1: Instalações e Imports\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "2Qu_QijLhFlN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R8IsHWKllAxS"
      },
      "outputs": [],
      "source": [
        "!pip install openai pandas python-dotenv -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "2: Imports e Configuração da API Key\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Arej9t4ihvWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv # Para carregar variáveis de ambiente, se você usar um .env no Colab\n",
        "import getpass # Para entrada segura da API Key"
      ],
      "metadata": {
        "id": "WkC3j_RzlDoZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configurações Iniciais ---\n",
        "\n",
        "# Tente carregar de um arquivo .env (opcional, se você fizer upload de um)\n",
        "# Crie um arquivo .env no seu Colab com a linha:\n",
        "# OPENAI_API_KEY=\"sua_chave_aqui\"\n",
        "# E faça o upload para a sessão do Colab.\n",
        "# Ou, use o input abaixo.\n",
        "load_dotenv()\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"A API Key da OpenAI (OPENAI_API_KEY) não foi encontrada no ambiente.\")\n",
        "    OPENAI_API_KEY = getpass.getpass(\"Por favor, insira sua OpenAI API Key e pressione Enter: \")\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    print(\"Erro Crítico: Nenhuma API Key da OpenAI foi fornecida. O programa não pode continuar.\")\n",
        "    # Em um notebook, podemos parar a execução ou levantar um erro\n",
        "    # raise ValueError(\"API Key da OpenAI não fornecida.\")\n",
        "    # Por ora, vamos apenas imprimir e deixar o usuário lidar com isso.\n",
        "else:\n",
        "    print(\"API Key da OpenAI carregada com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_Mom6dGhuwT",
        "outputId": "9af6cb74-cd42-4d26-8a42-df7494d3cef3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A API Key da OpenAI (OPENAI_API_KEY) não foi encontrada no ambiente.\n",
            "Por favor, insira sua OpenAI API Key e pressione Enter: ··········\n",
            "API Key da OpenAI carregada com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo da OpenAI que você deseja usar\n",
        "OPENAI_MODEL_ID = \"gpt-4o-mini\" # Usando o modelo GPT-4o mini\n",
        "\n",
        "# Inicializar o cliente da API da OpenAI\n",
        "client = None\n",
        "if OPENAI_API_KEY:\n",
        "    try:\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "        print(f\"Cliente OpenAI inicializado com sucesso para o modelo: {OPENAI_MODEL_ID}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao inicializar o cliente da API da OpenAI: {e}\")\n",
        "        client = None # Garante que o cliente não será usado se a inicialização falhar\n",
        "else:\n",
        "    print(\"Cliente OpenAI não pôde ser inicializado pois a API Key não está disponível.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOoe2f8_h1UY",
        "outputId": "e6a3e028-3271-404f-97b9-984f18525427"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cliente OpenAI inicializado com sucesso para o modelo: gpt-4o-mini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "3: Funções do Sistema RAG (semelhantes ao original)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "0ogcRskch39k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_information(query: str, user_profile: str) -> str:\n",
        "    \"\"\"\n",
        "    Simula a recuperação de informações com base na consulta e no perfil do usuário.\n",
        "    No Colab, esta função permanece conceitualmente a mesma.\n",
        "    \"\"\"\n",
        "    context = \"\"\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    # Lógica de recuperação (mantida do seu código original)\n",
        "    if \"enchente\" in query_lower:\n",
        "        if user_profile == \"Vítima\":\n",
        "            context = \"Situação de enchente: Procure um local alto e seguro. Evite contato com a água da enchente. Sinalize sua localização para equipes de resgate. Mantenha a calma. Telefones de emergência: Defesa Civil 199, Bombeiros 193.\"\n",
        "            if \"preso\" in query_lower:\n",
        "                context += \" Se estiver preso, não tente atravessar áreas alagadas por conta própria, aguarde o resgate. Se possível, avise sobre sua condição e localização exata.\"\n",
        "        elif user_profile == \"Morador\":\n",
        "            context = \"Alerta de enchente na região: Prepare um kit de emergência (água, comida, medicamentos, lanterna). Desligue a energia elétrica se houver risco de a água atingir sua casa. Mantenha-se informado pelos canais oficiais. Abrigos públicos: Ginásio Municipal, Escola Estadual Central.\"\n",
        "        elif user_profile == \"Familiar\":\n",
        "            context = \"Informações sobre enchentes: Para localizar familiares, entre em contato com a Defesa Civil (199) ou verifique listas em abrigos (Ginásio Municipal, Escola Estadual Central). Evite espalhar boatos, busque informações oficiais.\"\n",
        "    elif \"incêndio florestal\" in query_lower:\n",
        "        if user_profile == \"Vítima\":\n",
        "            context = \"Situação de incêndio florestal próximo: Se receber ordem de evacuação, saia imediatamente. Cubra nariz e boca com um pano úmido. Se não puder sair, procure um local aberto e longe da vegetação densa. Ligue para 193 (Bombeiros).\"\n",
        "        elif user_profile == \"Morador\":\n",
        "            context = \"Alerta de incêndio florestal: Mantenha a vegetação ao redor da casa limpa. Tenha rotas de fuga planejadas. Se avistar fumaça ou focos de incêndio, ligue para 193. Não faça queimadas.\"\n",
        "        elif user_profile == \"Familiar\":\n",
        "            context = \"Busca de informações sobre incêndio: Contate autoridades locais para status da situação e informações sobre áreas afetadas. Verifique notícias de fontes confiáveis.\"\n",
        "    else:\n",
        "        context = \"Informações gerais sobre segurança em desastres: Mantenha um kit de emergência, tenha um plano familiar, mantenha-se informado por fontes oficiais e siga as orientações das autoridades.\"\n",
        "    return context\n",
        "\n",
        "def generate_augmented_response(user_query: str, retrieved_context: str, user_profile: str) -> str:\n",
        "    \"\"\"\n",
        "    Gera uma resposta aumentada usando o cliente OpenAI.\n",
        "    As mensagens de erro são impressas no console do Colab.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        return \"Erro: O cliente da API da OpenAI não foi inicializado corretamente. Verifique sua API Key.\"\n",
        "\n",
        "    system_prompt = f\"\"\"Você é um assistente virtual especializado em orientar pessoas durante desastres naturais.\n",
        "    Sua missão é fornecer informações claras, precisas, empáticas e acionáveis.\n",
        "    Você DEVE usar as \"Informações Relevantes Recuperadas\" para basear sua resposta.\n",
        "    NÃO invente informações que não foram recuperadas, especialmente números de telefone, endereços específicos ou detalhes factuais não fornecidos no contexto.\n",
        "    Se as informações recuperadas não forem totalmente suficientes, você pode complementar com conselhos gerais de segurança relevantes para o contexto do desastre mencionado e o perfil do usuário, mas sempre indique claramente quando uma informação é um conselho geral e não parte dos dados recuperados.\n",
        "    Se a consulta for vaga, peça mais detalhes de forma gentil para poder ajudar melhor.\n",
        "    Responda diretamente à pergunta do usuário.\n",
        "    Priorize a segurança e o bem-estar. Seja empático, calmo e direto.\n",
        "    O perfil do usuário atual é: {user_profile}\"\"\"\n",
        "\n",
        "    user_content_prompt = f\"\"\"\n",
        "    **Consulta do Usuário:**\n",
        "    \"{user_query}\"\n",
        "\n",
        "    **Informações Relevantes Recuperadas (use estas informações para basear sua resposta):**\n",
        "    \"{retrieved_context}\"\n",
        "\n",
        "    Com base no seu papel, no perfil do usuário, na consulta e nas informações recuperadas, forneça a orientação adequada:\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n--- CONSOLE DEBUG: INÍCIO DE generate_augmented_response (OpenAI) ---\")\n",
        "    print(f\"CONSOLE DEBUG: Timestamp: {pd.Timestamp.now()}\")\n",
        "    print(f\"CONSOLE DEBUG: Usando OPENAI_MODEL_ID: {OPENAI_MODEL_ID}\")\n",
        "    print(f\"CONSOLE DEBUG: Comprimento System Prompt: {len(system_prompt)}, User Prompt: {len(user_content_prompt)}\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "\n",
        "    try:\n",
        "        print(f\"CONSOLE DEBUG: {pd.Timestamp.now()} - Tentando chamar OpenAI API com modelo de CHAT...\")\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=OPENAI_MODEL_ID,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_content_prompt}\n",
        "            ],\n",
        "            max_tokens=800,\n",
        "            temperature=0.4,\n",
        "            top_p=1.0,\n",
        "        )\n",
        "        full_response = response.choices[0].message.content.strip()\n",
        "\n",
        "        print(f\"CONSOLE DEBUG: {pd.Timestamp.now()} - Chamada à API OpenAI (Chat) retornou.\")\n",
        "        print(f\"CONSOLE DEBUG: {pd.Timestamp.now()} - Resposta bruta do modelo (primeiros 300 chars): '{full_response[:300]}...'\")\n",
        "        print(f\"CONSOLE DEBUG: {pd.Timestamp.now()} - Comprimento total da resposta bruta: {len(full_response)}\")\n",
        "        if response.usage:\n",
        "            print(f\"CONSOLE DEBUG: Uso de tokens: {response.usage}\")\n",
        "        print(\"--- CONSOLE DEBUG: FIM DE generate_augmented_response (SUCESSO OpenAI) ---\\n\")\n",
        "        return full_response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\n!!!!!!!!!! OCORREU UMA EXCEÇÃO AO CHAMAR A API DA OPENAI (CONSOLE LOG) !!!!!!!!!!!\")\n",
        "        error_type_name = type(e).__name__\n",
        "        print(f\"CONSOLE DEBUG: Timestamp da Exceção: {pd.Timestamp.now()}\")\n",
        "        print(f\"Tipo da Exceção: {error_type_name}\")\n",
        "        print(f\"Mensagem da Exceção: {str(e)}\")\n",
        "\n",
        "        # Tentar imprimir detalhes adicionais do erro, se disponíveis\n",
        "        if hasattr(e, 'http_status'):\n",
        "            print(f\"HTTP Status: {e.http_status}\")\n",
        "        if hasattr(e, 'code'):\n",
        "            print(f\"OpenAI Error Code: {e.code}\")\n",
        "        if hasattr(e, 'param'):\n",
        "            print(f\"Error Param: {e.param}\")\n",
        "        if hasattr(e, 'body'): # Tentar mostrar o corpo do erro bruto\n",
        "            print(f\"Error Body: {e.body}\")\n",
        "        elif hasattr(e, 'json_body'): # Se o corpo for JSON\n",
        "             print(f\"Error JSON Body: {json.dumps(e.json_body, indent=2)}\")\n",
        "\n",
        "        print(\"--- CONSOLE DEBUG: FIM DE generate_augmented_response (EXCEÇÃO OpenAI) ---\\n\")\n",
        "        return \"Desculpe, ocorreu um problema ao tentar gerar sua resposta com a OpenAI. Verifique o console para mais detalhes sobre o erro.\"\n"
      ],
      "metadata": {
        "id": "oVJttei0h-U1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "4: Interação com o Usuário e Execução Principal\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_y32SYHviAjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_colab_interaction():\n",
        "    print(\"--- Assistente Virtual para Desastres Naturais (Versão Colab) ---\")\n",
        "    print(f\"Utilizando o modelo: {OPENAI_MODEL_ID} (via OpenAI API)\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    if not client:\n",
        "        print(\"\\nAVISO: O cliente OpenAI não está pronto. Não será possível gerar respostas do assistente.\")\n",
        "        print(\"Por favor, verifique sua API Key na Célula 2 e execute-a novamente.\")\n",
        "        return\n",
        "\n",
        "    # Seleção de Perfil\n",
        "    user_profile_options = [\"Vítima\", \"Morador\", \"Familiar\"]\n",
        "    print(\"\\n👤 Selecione seu perfil:\")\n",
        "    for i, option in enumerate(user_profile_options):\n",
        "        print(f\"{i+1}. {option}\")\n",
        "\n",
        "    profile_choice = \"\"\n",
        "    while not profile_choice.isdigit() or not (1 <= int(profile_choice) <= len(user_profile_options)):\n",
        "        profile_choice = input(f\"Digite o número do seu perfil (1-{len(user_profile_options)}): \")\n",
        "        if not profile_choice.isdigit() or not (1 <= int(profile_choice) <= len(user_profile_options)):\n",
        "            print(\"Opção inválida. Por favor, tente novamente.\")\n",
        "    selected_profile = user_profile_options[int(profile_choice) - 1]\n",
        "    print(f\"Perfil selecionado: {selected_profile}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Entrada da Pergunta\n",
        "    user_query = input(\"❓ Descreva sua situação ou dúvida:\\n(Ex: Estou em uma área de enchente e a água está subindo. O que faço?)\\n\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    if not user_query:\n",
        "        print(\"⚠️ Você não digitou uma pergunta. Tente novamente.\")\n",
        "        return\n",
        "\n",
        "    print(\"⏳ Processando sua solicitação... Buscando informações e gerando orientação...\")\n",
        "\n",
        "    # 1. Recuperação de Informação (Simulada)\n",
        "    print(\"\\n--- Contexto Recuperado (Informações de Apoio) ---\")\n",
        "    retrieved_info = retrieve_information(user_query, selected_profile)\n",
        "    if retrieved_info:\n",
        "        print(f\"DEBUG: Buscando informações para: '{user_query}' (Perfil: {selected_profile})...\")\n",
        "        print(f\"```\\n{retrieved_info}\\n```\")\n",
        "        print(f\"DEBUG: Contexto recuperado: {retrieved_info}\")\n",
        "    else:\n",
        "        print(\"Nenhum contexto específico foi recuperado para esta consulta (usando informações gerais).\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # 2. Geração Aumentada\n",
        "    print(\"\\n💡 Orientação do Assistente:\")\n",
        "    final_response = generate_augmented_response(user_query, retrieved_info, selected_profile)\n",
        "    print(final_response)\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    print(\"\\n**Atenção:** Este é um assistente virtual para demonstração e apoio.\")\n",
        "    print(\"Em situações reais de emergência, **sempre siga as orientações das autoridades locais**\")\n",
        "    print(\"e contate os serviços de emergência (Bombeiros: 193, Defesa Civil: 199, SAMU: 192).\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "SByeB2jniEeG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "5: Executar a interação\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7N01ZZxxiGlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": # Garante que só execute se rodado como script principal\n",
        "    if client: # Só executa a interação se o cliente OpenAI foi inicializado\n",
        "        main_colab_interaction()\n",
        "    else:\n",
        "        print(\"\\nO assistente não pode ser executado porque o cliente OpenAI não foi inicializado.\")\n",
        "        print(\"Verifique a configuração da sua API Key na Célula 2 e execute-a novamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LokIlEEQiJvo",
        "outputId": "786e7459-db75-4c17-bb67-6a5c6057c519"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Assistente Virtual para Desastres Naturais (Versão Colab) ---\n",
            "Utilizando o modelo: gpt-4o-mini (via OpenAI API)\n",
            "------------------------------------------------------------\n",
            "\n",
            "👤 Selecione seu perfil:\n",
            "1. Vítima\n",
            "2. Morador\n",
            "3. Familiar\n",
            "Digite o número do seu perfil (1-3): 2\n",
            "Perfil selecionado: Morador\n",
            "------------------------------------------------------------\n",
            "❓ Descreva sua situação ou dúvida:\n",
            "(Ex: Estou em uma área de enchente e a água está subindo. O que faço?)\n",
            "Estou em uma área de enchente e a água está subindo. O que faço?\n",
            "------------------------------------------------------------\n",
            "⏳ Processando sua solicitação... Buscando informações e gerando orientação...\n",
            "\n",
            "--- Contexto Recuperado (Informações de Apoio) ---\n",
            "DEBUG: Buscando informações para: 'Estou em uma área de enchente e a água está subindo. O que faço?' (Perfil: Morador)...\n",
            "```\n",
            "Alerta de enchente na região: Prepare um kit de emergência (água, comida, medicamentos, lanterna). Desligue a energia elétrica se houver risco de a água atingir sua casa. Mantenha-se informado pelos canais oficiais. Abrigos públicos: Ginásio Municipal, Escola Estadual Central.\n",
            "```\n",
            "DEBUG: Contexto recuperado: Alerta de enchente na região: Prepare um kit de emergência (água, comida, medicamentos, lanterna). Desligue a energia elétrica se houver risco de a água atingir sua casa. Mantenha-se informado pelos canais oficiais. Abrigos públicos: Ginásio Municipal, Escola Estadual Central.\n",
            "------------------------------------------------------------\n",
            "\n",
            "💡 Orientação do Assistente:\n",
            "\n",
            "--- CONSOLE DEBUG: INÍCIO DE generate_augmented_response (OpenAI) ---\n",
            "CONSOLE DEBUG: Timestamp: 2025-06-04 20:03:30.815235\n",
            "CONSOLE DEBUG: Usando OPENAI_MODEL_ID: gpt-4o-mini\n",
            "CONSOLE DEBUG: Comprimento System Prompt: 970, User Prompt: 607\n",
            "---------------------------------------------------------\n",
            "CONSOLE DEBUG: 2025-06-04 20:03:30.815503 - Tentando chamar OpenAI API com modelo de CHAT...\n",
            "CONSOLE DEBUG: 2025-06-04 20:03:35.489278 - Chamada à API OpenAI (Chat) retornou.\n",
            "CONSOLE DEBUG: 2025-06-04 20:03:35.489798 - Resposta bruta do modelo (primeiros 300 chars): 'É muito importante agir rapidamente em situações de enchente. Aqui estão algumas orientações que você deve seguir:\n",
            "\n",
            "1. **Prepare um kit de emergência**: Certifique-se de ter água potável, alimentos não perecíveis, medicamentos necessários, uma lanterna e pilhas extras.\n",
            "\n",
            "2. **Desligue a energia elétr...'\n",
            "CONSOLE DEBUG: 2025-06-04 20:03:35.489852 - Comprimento total da resposta bruta: 975\n",
            "CONSOLE DEBUG: Uso de tokens: CompletionUsage(completion_tokens=220, prompt_tokens=344, total_tokens=564, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
            "--- CONSOLE DEBUG: FIM DE generate_augmented_response (SUCESSO OpenAI) ---\n",
            "\n",
            "É muito importante agir rapidamente em situações de enchente. Aqui estão algumas orientações que você deve seguir:\n",
            "\n",
            "1. **Prepare um kit de emergência**: Certifique-se de ter água potável, alimentos não perecíveis, medicamentos necessários, uma lanterna e pilhas extras.\n",
            "\n",
            "2. **Desligue a energia elétrica**: Se você perceber que a água pode atingir sua casa, desligue a energia elétrica para evitar riscos de choque elétrico.\n",
            "\n",
            "3. **Mantenha-se informado**: Acompanhe as atualizações sobre a enchente pelos canais oficiais, como rádio, televisão ou aplicativos de notícias.\n",
            "\n",
            "4. **Considere evacuar**: Se a situação estiver se tornando crítica, procure um abrigo público. Os locais disponíveis são o Ginásio Municipal e a Escola Estadual Central. \n",
            "\n",
            "5. **Evite áreas alagadas**: Não tente atravessar áreas inundadas a pé ou de carro, pois isso pode ser muito perigoso.\n",
            "\n",
            "Priorize sua segurança e a de sua família. Se precisar de mais ajuda ou informações, não hesite em perguntar.\n",
            "------------------------------------------------------------\n",
            "\n",
            "**Atenção:** Este é um assistente virtual para demonstração e apoio.\n",
            "Em situações reais de emergência, **sempre siga as orientações das autoridades locais**\n",
            "e contate os serviços de emergência (Bombeiros: 193, Defesa Civil: 199, SAMU: 192).\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}